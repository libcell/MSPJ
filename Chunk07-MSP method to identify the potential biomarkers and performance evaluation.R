
################################################################################
#    &&&....&&&    % Project: MSPJ approach for identification of DEGs         #
#  &&&&&&..&&&&&&  % Author: Bo Li, Huachun Yin, Jingxin Tao, Youjin Hao       #
#  &&&&&&&&&&&&&&  % Date: Jun. 1st, 2020                                      #
#   &&&&&&&&&&&&   %                                                           #
#     &&&&&&&&     % Environment: R version 3.5.3;                             #
#       &&&&       % Platform: x86_64-pc-linux-gnu (64-bit)                    #
#        &         %                                                           #
################################################################################

### ****************************************************************************
### code chunk number 07: MSP method and its performance evaluation..
### ****************************************************************************

#. load("setlist.RData")
#. deg.meta <- setlist$Meta.analysis
#. deg.svm <- setlist$SVM.RFE
#. deg.per <- setlist$Permutation

deg.int <- intersect(intersect(deg.meta, 
                               deg.svm), 
                     deg.per)

#. table(as.numeric(gsub("g", "", deg.meta)) > 500)
#. table(as.numeric(gsub("g", "", deg.svm)) > 500)
#. table(as.numeric(gsub("g", "", deg.per)) > 500)

setlist <- list(Meta.analysis = deg.meta, 
                SVM.RFE = deg.svm, 
                Permutation = deg.per)

save(setlist, file = "setlist.RData")

venn(setlist, 
     lty = 0, 
     col = "navyblue", 
     zcolor = 1:3, 
     lwd = 2, 
     box = FALSE)

### End of Step-02.
### ------------------------------------------------------------------------ ###

### ------------------------------------------------------------------------ ###
### Step-03. training the SVM models using k-fold Cross-Validation (inner loop). 

# Taking DEGs generated by SVM-RFE as example, and selecting top 1000 DEGs. 

#. sam.iris <- input[, c("sam.lab", deg.int)]
#. DT::datatable(sam.iris)
#. top.n <- 500
#. plot(1:top.n, 
#.      ylim = c(1, 25), 
#.      type = "n", 
#.      xlab = "Number of Differentially Expressed Genes", 
#.      ylab = "Number of Support Vectors")
#. for (i in 1:top.n) {
#.   sam.iris <- input[, c(1, ranked.feat[1:i] + 1)]
#.   model <- svm(sam.lab ~ ., 
#.                data = sam.iris, 
#.                kernel = "radial", 
#.                type = "C-classification", 
#.                probability = TRUE, 
#.                cross = 5)
#.   print(sum(model$nSV))
#.   points(i, sum(model$nSV), col = rainbow(top.n)[i], pch = 20)
#.   print(model$tot.accuracy)
#.   Sys.sleep(1)
#. }

### End of Step-02.
### ------------------------------------------------------------------------ ###

### ------------------------------------------------------------------------ ###
### Step-03. Constructing the SVM models and validation with nested k-fold CV. 

library(pROC)

sam.iris <- input[, c("sam.lab", deg.int)]

X <- sam.iris[, names(sam.iris) != "sam.lab"]

y <- as.character(sam.iris$sam.lab)

# please select the fold number, for k-fold CV. 

folds <- 10

test.fold <- split(sample(1:length(y)), 1:folds) # ignore warning

all.pred.tables <- lapply(1:folds, function(i) {
  
  test.id <- test.fold[[i]]
  
  X.train <- X[-test.id, ]
  
  y.train <- as.factor(y[-test.id])
  
  model <- svm(X.train, y.train, kernel = "radial", prob = TRUE, cross = 5) # some tuning may be needed
  
  predict.test <- predict(model, X[test.id, ], prob = TRUE)
  
  prob.benign <- attr(predict.test, "probabilities")[, 2]
  
  data.frame(y.test = y[test.id], y.pred = prob.benign) # returning this
  
})

full.pred.table <- do.call(rbind, all.pred.tables)

res.roc <- roc(full.pred.table$y.test, 
               full.pred.table$y.pred, 
               plot = TRUE, 
               legacy.axes = TRUE)

roc.df <- data.frame(TPP = res.roc$sensitivities * 100, 
                     FPP = (1 - res.roc$specificities) * 100, 
                     Thresholds = res.roc$thresholds)

# windowsFonts(A = windowsFont("Times New Roman"))

plot.roc(res.roc, 
         col = "#377EB8", 
         legacy.axes = TRUE, 
         percent = TRUE, 
         xlab = "False Positive Percentage", 
         ylab = "TRUE Positive Percentage", 
         lwd = 4, 
         print.auc = TRUE, 
         print.auc.x = 0.45, 
         print.auc.y = 0.45,
         auc.polygon = TRUE, 
         auc.polygon.col = "#377EB822") 

plot.roc(res.roc, 
         col = "#377EB8", 
         legacy.axes = TRUE, 
         percent = TRUE, 
         xlab = "False Positive Percentage", 
         ylab = "TRUE Positive Percentage", 
         lwd = 4, 
         print.auc = TRUE, 
         print.auc.x = 0.85, 
         print.auc.y = 0.85,
         auc.polygon = TRUE, 
         auc.polygon.col = "#377EB822", 
         add = TRUE) 

legend("bottomright", 
       legend = c("SVM-RFE", "LIMMA", "edgeR", "DESeq2"), 
       col = mypal2[1:4], 
       lwd = 4)

par(pty = "m")

# lines(perf, col = "green")

auc.value <- auc(res.roc)

auc.value

### End of Step-03.
### ------------------------------------------------------------------------ ###
