
################################################################################
#    &&&....&&&    % Project: MSPJ approach for identification of DEGs         #
#  &&&&&&..&&&&&&  % Author: Bo Li, Huachun Yin, Jingxin Tao, Youjin Hao       #
#  &&&&&&&&&&&&&&  % Date: Jun. 1st, 2020                                      #
#   &&&&&&&&&&&&   %                                                           #
#     &&&&&&&&     % Environment: R version 3.5.3;                             #
#       &&&&       % Platform: x86_64-pc-linux-gnu (64-bit)                    #
#        &         %                                                           #
################################################################################

### ****************************************************************************
### code chunk number 07: modeling and vilidation using nested k-fold Cross-validation.
### ****************************************************************************

### Reference: Implementing a class of permutation tests: the coin package, 2008. 
### Ref: https://rcompanion.org/handbook/K_01.html


deg.int <- intersect(intersect(deg.meta, deg.svm), deg.per)

table(as.numeric(gsub("g", "", deg.int)) > 500)

table(as.numeric(gsub("g", "", deg.meta)) > 500)
table(as.numeric(gsub("g", "", deg.svm)) > 500)
table(as.numeric(gsub("g", "", deg.per)) > 500)

setlist <- list(Meta.analysis = deg.meta, 
                SVM.RFE = deg.svm, 
                Permutation = deg.per)

save(setlist, file = "setlist.RData")


library(venneuler)
MyVenn <- venneuler(c(A=74344,B=33197,C=26464,D=148531,"A&B"=11797, 
                      "A&C"=9004,"B&C"=6056,"A&B&C"=2172,"A&D"=0,"A&D"=0,"B&D"=0,"C&D"=0))
MyVenn$labels <- c("A\n22","B\n7","C\n5","D\n58")
plot(MyVenn)
text(0.59,0.52,"1")
text(0.535,0.51,"3")
text(0.60,0.57,"2")
text(0.64,0.48,"4") 



### ------------------------------------------------------------------------ ###
### Step-01. preparing the datasets. 

eset <- get(load("seq.matrix.RData")); rm(seq.matrix)

sam.lab <- sapply(colnames(eset), function(x) strsplit(x, "-")[[1]][1])  
names(sam.lab) <- NULL

eset.mat <- as.data.frame(t(eset))
# eset.mat[1:9, 1:6]

input <- as.data.frame(cbind(sam.lab, eset.mat))

### End of Step-01.
### ------------------------------------------------------------------------ ###

### ------------------------------------------------------------------------ ###
### Step-02. training the SVM models using k-fold Cross-Validation (inner loop). 

# Taking DEGs generated by SVM-RFE as example, and selecting top 1000 DEGs. 

top.n <- 1000

plot(1:top.n, ylim = c(1, 25), type = "n", 
     xlab = "Number of Differentially Expressed Genes", 
     ylab = "Number of Support Vectors")

for (i in 1:top.n) {
  
  sam.iris <- input[, c(1, ranked.feat[1:i] + 1)]
  
  model <- svm(sam.lab ~ ., 
               data = sam.iris, 
               kernel = "radial", 
               type = "C-classification", 
               probability = TRUE, 
               cross = 5)
  
  print(sum(model$nSV))
  
  points(i, sum(model$nSV), col = rainbow(top.n)[i], pch = 20)
  
  print(model$tot.accuracy)
  
  Sys.sleep(1)
}

### End of Step-02.
### ------------------------------------------------------------------------ ###

### ------------------------------------------------------------------------ ###
### Step-03. Constructing the SVM models and validation with nested k-fold CV. 

X <- sam.iris[, names(sam.iris) != "sam.lab"]

y <- as.character(sam.iris$sam.lab)

# please select the fold number, for k-fold CV. 

folds <- 10

test.fold <- split(sample(1:length(y)), 1:folds) # ignore warning

all.pred.tables <- lapply(1:folds, function(i) {
  
  test.id <- test.fold[[i]]
  
  X.train <- X[-test.id, ]
  
  y.train <- as.factor(y[-test.id])
  
  model <- svm(X.train, y.train, kernel = "radial", prob = TRUE, cross = 5) # some tuning may be needed
  
  predict.test <- predict(model, X[test.id, ], prob = TRUE)
  
  prob.benign <- attr(predict.test, "probabilities")[, 2]
  
  data.frame(y.test = y[test.id], y.pred = prob.benign) # returning this
  
})

full.pred.table <- do.call(rbind, all.pred.tables)

res.roc <- roc(full.pred.table$y.test, full.pred.table$y.pred)

plot(res.roc, col = "red") 
# lines(perf, col = "green")

auc.value <- auc(res.roc)

auc.value

### End of Step-03.
### ------------------------------------------------------------------------ ###


# ---------------------------------------------------------------------------- #

library(ROCR)

test.id <- sample(1:25, 13, replace = FALSE)

str(model)

training.X <- X[-test.id, ]
training.y <- y[-test.id]

test.X <- X[test.id, ]
test.y <- y[test.id]

model2 <- svm(x = training.X, 
              y = training.y, 
              kernel = "radial", 
              type = "C-classification", 
              probability = TRUE, 
              cross = 2)

model2$accuracies

model5 <- svm(x = training.X, 
              y = training.y, 
              kernel = "radial", 
              type = "C-classification", 
              probability = TRUE, 
              cross = 5)

model5$accuracies

model3 <- svm(x = training.X, 
              y = training.y, 
              kernel = "radial", 
              type = "C-classification", 
              probability = TRUE, 
              cross = 3)

model3$accuracies

predict.y1 <- predict(object = model2, newdata = test.X, probability = TRUE)
predict.y2 <- predict(object = model5, newdata = test.X, probability = TRUE)

table(predict.y1, test.y)
table(predict.y2, test.y)

# End. 

